Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting DECEMBER 2022   Australian Human Rights Commission 2022. The Australian Human Rights Commission encourages the dissemination and exchange of information presented in this publication. All material presented in this publication is licensed under the Creative Commons Attribution 4.0 International Licence, with the exception of photographs and images the Commission s logo, any branding or trademarks where otherwise indicated. To view a copy of this licence, visit In essence, you are free to copy, communicate and adapt the publication, as long as you attribute the Australian Human Rights Commission and abide by the other licence terms. Please give attribution to Australian Human Rights Commission 2022. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting December 2022 ISBN 978 1 925917 75 8 Acknowledgments The Australian Human Rights Commission thanks our partner, the Actuaries Institute, for their assistance with the development of the Guidance Resource, and its members and insurance industry representatives, who participated in consultations for sharing their knowledge, expertise and experience. The Human Rights Commissioner thanks the following staff of the Australian Human Rights Commission for their contributions Michael Badorrek, Darren Dick, Graeme Edgerton, and Llewellyn Spink. This publication can be found in electronic format on the Australian Human Rights Commission s website at For further information about the Australian Human Rights Commission or copyright in this publication, please contact Australian Human Rights Commission GPO Box 5218 SYDNEY NSW 2001 Telephone 02 9284 9600 Email communications humanrights.gov.au For further information about the Actuaries Institute, please contact Actuaries Institute Level 2, 50 Carrington Street Sydney NSW 2000 Telephone 61 2 9239 6100 Email actuaries actuaries.asn.au Design and layout Dancingirl Designs Cover image and internal photography Adobe Stock  Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting December 2022 Australian Human Rights Commission 2022  Contents Forewords 5 Australian Human Rights Commission 5 Actuaries Institute of Australia 6 1 Introduction 7 1.1 A need for guidance 7 2 About the Guidance Resource 9 2.1 Who is the Guidance Resource for 9 2.2 Why should I consider the Guidance resource 9 3 What does the law say 11 3.1 What is discrimination 11 a Protected attributes 11 b Direct discrimination 11 c Indirect discrimination 11 3.2 When is discrimination unlawful 14 3.3 Exemptions and exceptions 15 a Insurance exemptions 15 b Unjustifiable hardship exception 16 3.4 Has unlawful discrimination occurred 18 3.5 What about state and territory laws 19 4 Artificial Intelligence and discrimination 21 4.1 What is AI How is it used 21 4.2 Algorithmic bias 21 4.3 Mitigating against algorithmic bias and discrimination 22 a Data 22 b Models 24 5 Case Studies Challenges for insurers 27 5.1 Case Study Car Insurance 27 a Part A 27 b Part B 30 5.2 Case Study Travel Insurance 32 5.3 Case Study Life Insurance 35 6 Practical tips to avoid unlawful discrimination when using AI 39 Further Resources 41 Appendix 1 Key sections under the Discrimination Acts 43  FOREWORDS Australian Human Rights Commission When approached by the Actuaries Institute the Institute , the Australian Human Rights Commission the Commission welcomed this opportunity to partner with them on the development of this Guidance Resource on artificial intelligence AI and discrimination in insurance pricing and underwriting the Guidance Resource . AI promises faster and smarter decision making. However, the use of AI carries with it certain risks, including the risk of discrimination. At the federal level, unlawful discrimination is prohibited by the Age Discrimination Act 2004 Cth , Disability Discrimination Act 1992 Cth , Racial Discrimination Act 1975 Cth , and Sex Discrimination Act 1984 Cth together, the Discrimination Acts . Yet there is recognition in most of these acts that discrimination by insurers will not be unlawful in certain circumstances broadly when it is reasonable and based on actuarial or statistical data. Data and modelling are at the heart of many decisions made by insurers. The Discrimination Acts apply to such decisions whether or not they are made using AI. Nonetheless, the Commission has heard concerns from the community regarding the uncertainty of how the Discrimination Acts apply to the use of AI in this context. The Guidance Resource provides information on the Discrimination Acts, the risks of discrimination arising from the use of AI, and how to mitigate against these risks. It provides practical guidance for insurers on complying with the Discrimination Acts when using AI for insurance pricing and underwriting. On behalf of the Commission, I thank the Institute for their valued contributions to this work. I also thank the Institute members and insurance industry representatives for the advice and feedback they provided during our consultation process. I look forward to insurers using this Guidance Resource to assist them in complying with the Discrimination Acts when making pricing and underwriting decisions using AI, and in delivering fairer outcomes for their customers. Lorraine Finlay Human Rights Commissioner Lorraine Finlay Human Rights Commissioner Australian Human Rights Commission Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 5  Actuaries Institute of Australia The Actuaries Institute welcomes the opportunity to partner with the Australian Human Rights Commission on the development of this Guidance Resource. Actuaries working in insurance, and particularly those involved with pricing and underwriting, currently face significant uncertainty around how to comply with Australia s antidiscrimination laws, especially in an increasingly digital economy. This Guidance Resource is designed to assist them in their professional roles. It may also be helpful for many other professionals. The time is right This guidance is much needed. While Australia s anti discrimination laws are longstanding, there is limited guidance and case law available to practitioners. The complexity arising from differing antidiscrimination legislation in Australia at the federal, State and Territory levels, compounds the challenges facing Actuaries, and may reflect an opportunity for reform. Emerging megatrends make guidance critical Several intersecting megatrends make this lack of guidance more problematic, and urgent to address. These trends include the explosive growth of big data , increased use and power of artificial intelligence and algorithmic decision making, and growing and changing consumer awareness and expectations about what is fair . Actuaries seek to responsibly leverage the potential benefits of these digital megatrends, for the consumer, society and business. To do so with confidence, however, requires authoritative guidance to make the application of AI clearer in order to comply with the law. What this Guidance Resource means for you While this Guidance Resource will answer many questions practitioners have, it cannot address all potential situations. The Institute hopes that this publication encourages further societal and C suite discussion of algorithmic discrimination, both within and outside of insurance. We hope that further guidance is commissioned in order that the professionals building the algorithms that drive important decisions in our society have clarity around society s expectations from those decisions. Elayne Grace Chief Executive Officer Elayne Grace Chief Executive Officer Actuaries Institute of Australia 6  This Guidance Resource has been developed by the Australian Human Rights Commission the Commission , in partnership with the Actuaries Institute Institute , to provide guidance to professionals and businesses on complying with federal anti discrimination legislation in relation to use of artificial intelligence AI in insurance pricing and underwriting decisions. This Guidance Resource uses the term AI in a consistent manner to the Commission s Human Rights and Technology Final Report Human Rights and Technology Report to broadly refer to a cluster of technologies and techniques, which include some forms of automation, machine learning or algorithmic decision making.1 The Guidance Resource provides information about the operation of the Age Discrimination Act 2004 Cth , Disability Discrimination Act 1992 Cth , Racial Discrimination Act 1975 Cth , and Sex Discrimination Act 1984 Cth in relation to the use of the artificial intelligence in insurance pricing and underwriting decisions information about the risks of algorithmic bias and discrimination arising from the use of artificial intelligence practical guidance for insurers for avoiding unlawful discrimination when using artificial intelligence. 1.1 A need for guidance In 2021, the Commission published its Human Rights and Technology Report. The report was the product of a major project examining the human rights impacts of new and emerging technologies, including AI informed decision making. In response to feedback received during the project s extensive consultation process, the Commission recommended in its report that it be resourced to produce guidelines for government and non government bodies on complying with federal anti discrimination laws in the use of AI informed decision making. The Institute, the peak professional body representing the actuarial profession in Australia, welcomed this recommendation. The Institute had made a submission to the Commission s consultation process2 noting areas of uncertainty and the need for improved guidance. The Institute s working party on anti discrimination also published a conference paper3 highlighting some of these areas of uncertainty. Following an approach for collaboration from the Institute, the Commission partnered with the Institute to develop this Guidance Resource. It focuses on the use of AI in insurance pricing and underwriting decisions and was informed by a targeted consultation process of its members and industry experts. The Commission conducted a survey of Institute members in 2022 which revealed that over 70 of respondents were at least moderately concerned with the risk of breaching federal anti discrimination laws when using AI. This Guidance Resource aims to assist in addressing those concerns. The Commission thanks the Actuaries Institute for its involvement, and those who participated in the consultations for sharing their knowledge and expertise. 1 Introduction Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 7   2 About the Guidance Resource 2.1 Who is the Guidance Resource for The Guidance Resource is intended to provide guidance to professionals and businesses who are using AI when making insurance pricing and underwriting decisions. It has been developed for actuaries, insurance companies, their staff, and others working in this area. Ultimately, an insurer s board of directors and corporate officers are responsible for ensuring the insurer s compliance with anti discrimination law. This Guidance Resource may help to create a common understanding between such executives and practitioners of these issues, aiding discussion of it within insurers. The Guidance Resource may also assist customers of insurance companies and members of the public in understanding their rights in this context. 2.2 Why should I consider the Guidance resource The Guidance Resource provides information and practical guidance to assist decision makers to comply with their obligations under federal anti discrimination legislation when using AI in insurance pricing and underwriting decisions. There are important reasons for following the Guidance Resource. It is against the law to discriminate against a person because of protected attributes, such as their age, sex, race, or disability, when providing insurance services unless an exemption applies. The Guidance Resource does not constitute legal advice. It only provides general guidance and is not a definitive legal answer to all issues of discrimination that may arise. There is limited legal certainty about how a court may decide many of these issues. Given these constraints, the Guidance Resource indicates when the Commission considers that conduct may or is likely to constitute unlawful discrimination. Organisations or individuals should seek their own independent legal advice if they have concerns regarding their compliance with federal, state or territory anti discrimination legislation. An organisation or individual will not be protected from a finding of unlawful discrimination by claiming that they complied with, or relied on, the Guidance Resource. The Commission considers however that acting in accordance with the Guidance Resource represents good practice and may be a factor considered by the courts, should a matter be considered in a judicial forum, particularly when considering if any discrimination was reasonable in the circumstances. This is an area of evolving practice, and it is recommended that insurers stay up to date with any developments to current practices and the law. Some insurance products such as private health insurance and Compulsory Third Party CTP insurance are underwritten as part of statutory schemes which may impose significant restrictions over terms, conditions, or prices of policies. This Guidance Resource is written in general terms considering typical insurance products, and does not consider the specific details that apply to such products or schemes. Institute members may find it a useful resource to assist in complying with relevant laws as required under the Institute s Code of Conduct. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 9   3 What does the law say This section provides a brief overview of the Australia s federal anti discrimination legislation, which is contained in a Age Discrimination Act 2004 Cth ADA b Disability Discrimination Act 1992 Cth DDA c Racial Discrimination Act 1975 Cth RDA d Sex Discrimination Act 1984 Cth SDA together, the Discrimination Acts . In addition to the Discrimination Acts, insurers also have obligations under state and territory anti discrimination legislation see section 3.5 .4 3.1 What is discrimination Under the Discrimination Acts, discrimination includes both direct and indirect discrimination on the basis of certain personal characteristics, known as protected attributes. a Protected attributes The Discrimination Acts respectively make it unlawful to discriminate against persons because of the following protected attributes a ADA age5 b DDA disability6 c RDA race, colour, descent, national or ethnic origin, or immigrant status7 d SDA sex, sexual orientation, gender identity, intersex status, marital or relationship status, pregnancy or potential pregnancy, breastfeeding, or family responsibilities.8 However, there are exemptions in some of the Discrimination Acts which provide that discrimination by insurers may be lawful in certain circumstances see section 3.3 . b Direct discrimination Direct discrimination involves treating a person less favourably than another person because of a protected attribute in circumstances that are the same or not materially different.9 For example, refusing to insure someone because they have a disability would be direct discrimination. In simple terms, the question for insurers will usually be did the insurer treat a customer with a protected attribute less favourably than a customer without a protected attribute because of that protected attribute Whilst a customer claiming discrimination must show that the less favourable treatment was because of the protected attribute, they do not have to show that the insurer had an intention or motive to discriminate. Where the customer s treatment may be due to two or more reasons including the protected attribute , then it is taken to be done by reason of the protected attribute regardless of whether that was the dominant or substantial reason .10 c Indirect discrimination Indirect discrimination occurs when a term, condition, requirement, or practice for simplicity, we will subsequently refer only to a requirement , that applies to everyone disadvantages people with a protected attribute, and the requirement is not reasonable in the circumstances.11 Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 11  For example, an insurer who requires all customers to prove their identity by providing a driver s licence is likely to indirectly discriminate against anyone who is unable to drive because of a disability. This is because the person with disability is unable to comply with the requirement, with the result that they may be denied insurance services, and it would be reasonable to allow them to prove their identity in another way. While there are some differences between the Discrimination Acts in their definitions of indirect discrimination see Appendix 1 , broadly, the key elements to indirect discrimination are 1. A requirement is imposed, or proposed to be imposed. For the RDA and DDA, it must also be shown that the person with the protected attribute does not, or cannot or is not able to, comply with the requirement. 2. The requirement has the effect, or is likely to have the effect, of disadvantaging people with a protected attribute. 3. The requirement is not reasonable in the circumstances.12 Requirement The Discrimination Acts refer respectively to the imposition of a term, condition or requirement RDA , requirement or condition DDA , or condition, requirement or practice ADA and SDA . These terms are interpreted broadly to cover any form of qualification or prerequisite.13 Nonetheless, the relevant requirement should be identified with some precision.14 In the context of providing goods and services, a requirement is imposed where there is some stipulation or set of circumstances that must be obeyed or endured if those goods or services are to be acquired, used or enjoyed .15 Failure or inability to comply The failure or inability of the customer to comply with the requirement is necessary to establish unlawful conduct under the RDA and DDA. Under the RDA, it is necessary to show that the person does not or cannot comply with the requirement. This should be understood with its ordinary meaning a person who has not complied with the requirement will generally be a person who does not comply with the requirement16 The DDA provides that because of the disability, the aggrieved person does not or would not comply, or is not able to, or would not be able to comply , with the requirement. Here, it must be shown that the failure or inability to comply was because of the disability. The courts have emphasised the need to take a broad and liberal approach when considering this issue.17 In assessing a person s inability to comply with a requirement, it is a person s practical as opposed to theoretical or technical ability to comply that is most relevant.18 Moreover, in relation to the DDA, the courts have more broadly considered whether the complainant would suffer serious disadvantage in complying with the requirement, rather than just their technical ability to comply.19 3 What does the law say 12  Disadvantaging Disadvantaging is not defined under the ADA, DDA or SDA. While this term is not expressly used in the RDA, the RDA also considers the disadvantageous impact of the requirement. The RDA refers to a requirement that has the purpose or effect of nullifying or impairing the recognition, enjoyment or exercise, on an equal footing, of any human right or fundamental freedom in the political, economic, social, cultural or any other field of public life for simplicity, we will subsequently describe this as impairing their human rights .20 Ultimately, whether a requirement disadvantages a person with a protected attribute, or impairs their human rights, is a matter of evidence. The necessary evidence will depend on the individual circumstances. In academic research relating to AI informed decision making, there are conflicting views about how disadvantage or, more generally, fairness ought to be measured, and on the incompatibility between different forms of such measurement.21 While an insurer may have determined its AI informed decisions are fair according to its own metrics, there may be alternative opinions as to whether this is correct. Such an issue would also be a matter for evidence for the court, if an unlawful discrimination matter were litigated, when considering whether the requirement disadvantages, and also whether it is reasonable in the circumstances. Unfairness is a broader concept than discrimination. While discrimination is unfair, acting unfairly does not necessarily constitute discrimination, and may not be in breach of the Discrimination Acts. However, it may give rise to other risks for insurers, such as reputational risks or loss of customers. While these are beyond the scope of this Guidance Resource, they are issues Which an insurer may wish to consider. Reasonable in the circumstances In determining whether the requirement is reasonable in the circumstances, all relevant circumstances must be taken into account.22 The SDA states that the following non exhaustive list of factors should be taken into account when deciding whether a condition, requirement or practice is reasonable in the circumstances a the nature and extent of the disadvantage resulting from the imposition, or proposed imposition, of the condition, requirement or practice and b the feasibility of overcoming or mitigating the disadvantage and c whether the disadvantage is proportionate to the result sought by the person who imposes, or proposes to impose, the condition, requirement or practice. The ADA, DDA and RDA do not include such express guidance. While the relevant factors will depend on the circumstances of each case, the following factors may be relevant to assessing whether the requirement is reasonable the nature and effect of the requirement23 the financial burden on the alleged discriminator to accommodate the needs of the person alleging discrimination24 the availability of alternative methods of achieving the alleged discriminator s objectives without the requirement,25 however the existence of reasonable alternatives does not, by itself, mean a requirement is unreasonable26 Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 13   issues of effectiveness, efficiency, and convenience in performing an activity or completing a transaction and the cost of not imposing the discriminatory requirement or substituting another requirement.27 In assessing reasonableness, the courts have also outlined the following principles 28 The criterion is an objective one, which requires the court to weigh the nature and extent of the discriminatory effect, on the one hand, against the reasons advanced in favour of the requirement or condition on the other.29 The test of reasonableness is less demanding than one of necessity, but more demanding than a test of convenience.30 The test is reasonableness, not correctness, or whether the alleged discriminator could have made a better or more informed decision .31 A decision may not be reasonable even if it has a  logical and understandable basis .32 Under the SDA, DDA and ADA, once the customer alleging discrimination shows that a requirement disadvantages people with the relevant attribute, the insurer will have the burden of proving that the requirement is reasonable in the circumstances.33 However, under the RDA, the customer alleging discrimination must also show the requirement is not reasonable in the circumstances.34 3.2 When is discrimination unlawful The Discrimination Acts make discrimination on the basis of a protected attribute unlawful in relation to the provision of goods, services and facilities, unless an exemption or exception applies.35 This includes services relating to insurance.36 Unless an exemption or exception applies, insurers must not discriminate on the basis of protected attributes by refusing to supply services in the terms and conditions on which services are provided, or in the manner in which their services are provided.37 Discrimination occurs at the time of the discriminatory act. In insurance, this might be the refusal to provide cover, an offer of a policy on unreasonable terms, or a refusal to pay a claim.38 These matters are often interconnected, as a claim might be refused based on an exclusion contained within the terms and conditions of a policy. However, the date of the insurance contract or policy may not always be decisive. For example, if a customer s contract predates the Discrimination Acts and contains a discriminatory exclusion, and the insurer now refuses a customer s claim based on that clause, the refusal may be covered by the Acts. It would then have to be determined whether the refusal was in breach of the Discrimination Acts, but the claim could not necessarily be defeated simply because the contract predates that legislation. 3 What does the law say 14  3.3 Exemptions and exceptions a Insurance exemptions There is recognition in the Discrimination Acts that some discrimination by insurers may be necessary. The ADA, DDA and SDA provide exemptions which mean that discrimination relating to insurance services may not be unlawful in some circumstances. No such exemption applies under the RDA. ADA and DDA exemptions The ADA39 and DDA40 provide that discrimination on the basis of age or disability in relation to provision of insurance by either refusing to offer a product, or in respect of the terms or conditions on which the product is offered or may be obtained, is not unlawful if the discrimination is based upon actuarial or statistical data on which it is reasonable to rely, and the discrimination is reasonable having regard to the matter of the data and other relevant factors the data exemption or in a case where no such actuarial or statistical data is available and cannot reasonably be obtained the discrimination is reasonable having regard to any other relevant factors the no data exemption . An insurer who relies on the exemption must be able to show that the requirements of either the data exemption or no data exemption are met. The data exemption An insurer who relies on the data exemption must be able to show that the data was available and relied upon at the time the decision was made. Insurers should keep accurate records of data relied upon. If a complaint of discrimination is made to the Commission, an insurer may be required to disclose the source of the data as part of the Commission s conciliation process.41 The data may also need to be produced if the discrimination complaint proceeded to court. Insurers should make an objective judgment about the nature and quality of the actuarial or statistical data .42 It may not be reasonable to rely on data that is out of date, qualified, incomplete, discredited, based on an insufficient sample size, or not directly applicable to the particular situation.43 Data that may be reasonable to rely upon includes underwriting manuals with information about the nature and degree of extra risk of insuring particular groups provided the data used to populate them is complete and up to date local data, such as government studies, census statistics, studies reported in medical journals, and insurance studies with data from a reliable source44 international studies, particularly if local data is insufficient or it can be shown that the international data remains reasonably applicable in Australia.45 Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 15  In addition to being based on appropriate data, any discrimination must also be reasonable in light of other relevant factors. A relevant factor would include any matter which is rationally capable of bearing upon whether the discrimination is reasonable .46 This includes factors that may increase the risk to the insurer as well as those that may reduce it. These may include medical opinions, the customer s circumstances, other professional opinions, actuarial advice or opinions, practice of others in the insurance industry, and commercial judgement. The no data exemption These exemptions are sequential, such that the data exemption must be considered before the no data exemption. If relevant data is available or could reasonably be obtained, insurers cannot rely on the no data exemption. If there is no data, the no data exemption will apply where the discrimination is objectively reasonable having regard to any other relevant factors. These factors may include practical and business considerations whether less discriminatory options were available the customer s particular circumstances the objects of the DDA and ADA, especially the object of eliminating disability and age discrimination all other relevant factors of the case. SDA data exemption A data exemption similarly applies under section 41 of the SDA in relation to discrimination on the basis of a customer s sex.47 Discrimination by an insurer against a client on the basis of their sex in relation to the terms on which an insurance policy is offered to, or may be obtained by, the client is not unlawful if it is based on actuarial or statistical data from a source on which it is reasonable to rely and the discrimination is reasonable having regard to the data. However, the SDA does not include a no data exemption . As such, no exemption is available for insurers to discriminate on the basis of sex where there is no actuarial or statistical data. As above, an insurer may be required to disclose the data to the Commission if a discrimination complaint is made to it,48 or if the matter proceeded to court. Additionally, under the SDA, regardless of whether a complaint has been made, the insurer can be required to disclose the relevant data to the customer if requested in writing.49 No similar requirement exists under the ADA or DDA. b Unjustifiable hardship exception Unjustifiable hardship is a defence to a claim of discrimination under the DDA. The DDA provides that it is not unlawful for a person the discriminator , including an insurer, to discriminate against a person with a disability if avoiding the discrimination would cause unjustifiable hardship on the discriminator.50 3 What does the law say 16  In determining whether the hardship is unjustifiable, all relevant circumstances of a particular case are taken into account, which include, but are not limited to the nature of the benefit or detriment likely to accrue to, or to be suffered by any person concerned. For example, if insurance cover was provided, this could include the benefit to the customer with disability, the benefit to the community, and the financial burden to the insurer the effect of the disability of any person concerned any costs or other disadvantages of providing cover, including consideration of the financial circumstances of the insurer and the availability of financial and other assistance to the insurer, and the terms of any relevant action plan developed by the insurer under section 64 of the DDA.51 This exception recognises that some hardship on an insurer will be justifiable. If the financial burden on an insurer is minor as opposed to very significant, such that the insurer s financial viability is at risk , then it is not likely to fall within the exception.52 Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 17  3.4 Has unlawful discrimination occurred Has a person been treated less favourably on the basis of a protected attribute e.g. age, disability, race, or sex see section 3.1 a in relation to the provision of services by an insurer by refusing to supply services in the terms and conditions on which services are provided, or in the manner in which their services are provided. See sections 3.1 b and 3.2 Data exemption Is the discrimination on the basis of age, disability or sex Is it based on actuarial or statistical data on which it is reasonable to rely Is it reasonable having regard to the matter of the data and other relevant factors See section 3.3 a No data exemption Is the discrimination on the basis of age or disability Is there no actuarial or statistical data available on which it is reasonable for the insurer to rely and such data cannot reasonably be obtained Is the discrimination reasonable having regard to any other relevant factors See section 3.3 a Unjustiﬁable hardship exception Is the discrimination on the basis of a customer s disability Would avoiding the discrimination cause the insurer unjustiﬁable hardship See section 3.3 b DIRECT DISCRIMINATION INDIRECT DISCRIMINATION EXEMPTIONS EXCEPTIONS 1 Has a requirement been imposed which disadvantages a person because of their protected attribute e.g. age, disability, race, or sex see section 3.1 a , and which is not reasonable in the circumstances, in relation to the provision of services by an insurer by refusing to supply services in the terms and conditions on which services are provided, or in the manner in which their services are provided. See sections 3.1 c and 3.2 2 33 Does an exemption or an exception apply IT IS UNLIKELY THAT UNLAWFUL DISCRIMINATION HAS OCCURED UNLAWFUL DISCRIMINATION MAY HAVE OCCURED NO NO NO NO YES YES YES 3 What does the law say 18  3.5 What about state and territory laws In addition to the Discrimination Acts, insurers also have obligations under relevant state and territory anti discrimination legislation.53 The Discrimination Acts do not exclude the operation of state and territory anti discrimination legislation where it is capable of operating alongside the Discrimination Acts.54 This means that state and territory anti discrimination legislation might impose different, or stricter, obligations. They may also provide protection to a wider range of protected attributes than the Discrimination Acts. While it is beyond the scope of this Guidance Resource to examine state and territory anti discrimination laws in detail,55 the following table provides an overview of the relevant legislation and authorities with links to specific resources in the endnotes that insurers may wish to consult in assessing their compliance with state and territory laws. State or territory Anti discrimination legislation Relevant authority Australian Capital Territory Discrimination Act 1991 ACT ACT Human Rights Commission56 New South Wales Anti Discrimination Act 1977 NSW Anti Discrimination Board of NSW57 Northern Territory Anti Discrimination Act 1992 NT Northern Territory Anti Discrimination Commission58 Queensland Anti Discrimination Act 1991 Qld Anti Discrimination Commission Queensland59 South Australia Equal Opportunity Act 1984 SA Equal Opportunity Commission60 Tasmania Anti Discrimination Act 1998 Tas Equal Opportunity Tasmania61 Victoria Equal Opportunity Act 2010 Vic Victorian Equal Opportunity and Human Rights Commission62 Western Australia Equal Opportunity Act 1984 WA Equal Opportunity Commission63 Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 19   4 Artificial Intelligence and discrimination 4.1 What is AI How is it used While the term AI is widely used, it does not have a precise, universally accepted definition. This Guidance Resource uses the term AI in a consistent manner to the Human Rights and Technology Report to broadly refer to a cluster of technologies and techniques, which include some forms of automation, machine learning or algorithmic decision making.64 Insurers have long relied on data, statistical analysis, and models to determine risk and set prices for their policies, even prior to modern computing. Interpreted broadly, a wide range of technologies and techniques traditionally used by insurers in pricing or underwriting may be considered AI, or may otherwise form part of AI informed decision making. While the use of data and models by insurers is not new, AI has the capacity to analyse large volumes of granular data more quickly, and to create more complex and potentially more accurate models. AI systems also include techniques not traditionally used in insurance ratemaking such as machine learning, including deep learning or neural networking processing. This means that while the risks may be heightened, they are not new. This Guidance Resource refers to AI informed decision making . This means a decision, or decision making process, where AI is a material factor in the decision, and where the decision has a legal or similarly significant effect for an individual. The decision does not have to be wholly made by AI the decision making process could involve both AI and human involvement, but the involvement of AI must be material or significant. In the insurance context, AI may be used in a wide range of different ways, including in relation to pricing, underwriting, marketing, customer service or internal operations. This Guidance Resource focuses on the use of AI in the context of pricing and underwriting decisions as these decisions are more likely both to use AI and to have a legal or similarly significant effect for an individual. Such decisions may also be more likely to give rise to discrimination complaints from customers. However, many of the general principles outlined in this Guidance Resource may also apply to the use of AI informed decision making in other contexts. 4.2 Algorithmic bias AI can enable good, data driven decision making. It can be used to analyse large amounts of data quickly, accurately and cost effectively. However, whilst AI promises faster and smarter decision making, AI informed decision making carries with it certain risks. It can assist in identifying and addressing bias or prejudice that can be present in human decision making, but it can also perpetuate or entrench such problems. It can sometimes result in decisions that are unfair or even discriminatory. This is often referred to as the risk of algorithmic bias. Algorithmic bias does not have an agreed meaning but is usually understood to refer to the situation where AI is used to produce outputs that treat one group less favourably than another, without suitable justification.65 Algorithmic bias can include statistical bias and may result in unfairness and, in some circumstances, unlawful discrimination. It can arise through problems with the data being used by the AI system, or problems with the AI system itself. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 21  4.3 Mitigating against algorithmic bias and discrimination The effects of algorithmic bias may be avoided through rigorous design, testing and monitoring of an AI system.  AI systems should generally be designed, where possible, to avoid discriminatory outcomes. For insurers, AI systems may necessarily include some forms of discrimination, so should be designed to avoid unlawful discrimination. They should be monitored and tested throughout their lifecycle to ensure they continue to do so, and any identified problems are appropriately addressed. In this way, it is important that relevant technical staff and management have training in relation to discrimination law to ensure that problems can be identified and addressed. In addition to the above, there are various mitigation strategies that can be employed in relation to the data and models used by AI systems to address algorithmic bias and prevent unlawful discriminatory outcomes. This section provides some examples of such strategies, but is not intended to be an exhaustive list. This is an emerging field with conflicting views particularly regarding measuring fairness, as discussed above and, at times, mutually contradictory proposals. Insurers should keep up to date with the emerging literature, and ensure they carefully consider their specific context in justifying any approach taken. Insurers should record any steps taken to mitigate against unlawful discrimination, and the reasons for those decisions. This information may assist a court in understanding the reasons for any unfavourable treatment, determining whether any indirect discrimination was reasonable in the circumstances, or determining whether any discrimination based on data was reasonable, and if a relevant exemption applies. a Data Insurance pricing and underwriting decisions are driven by data. This is recognised by the insurance exemptions under the ADA, DDA and SDA, which, in certain circumstances, allow an insurer to discriminate if it is based on actuarial or statistical data. Data can be internal or external to the insurer. The term data covers raw data but can also cover outputs from other models and analysis undertaken including, for example, government studies and academic studies that are used as inputs into AI informed decision making systems, as well as any resulting interpretation or professional judgement of the data and analysis. It is important to understand the potential issues of a data set used to train an AI system. Steps may need to be taken to address these issues and avoid discriminatory outcomes, such as acquiring more data particularly from underrepresented segments of the population , preprocessing the data, not including data relating to protected attributes within customer decisions to remove direct discrimination, or applying suitable mitigation strategies within algorithm or model construction to remove indirect discrimination. i Acquire more representative, more appropriate, or additional data The quality of the data that is used to train an AI informed decision making system will affect the quality of the decisions. This is sometimes called the garbage in, garbage out problem. 4 Artificial Intelligence and discrimination 22  The source of data is critical, and must be relevant for the model and purpose being considered. As a result, local data would usually be more likely to be applicable than international data. However, international data may be relied on provided it remains reasonably applicable to Australia.66 Consideration should be given to how international data would need to be modified for applicability before use. Data sets may be inaccurate if affected by selection bias, such that the data is not representative of a population. Notably, individuals or groups that have faced systemic discrimination may be inaccurately represented, or under represented in data sets. This may also be true of model outputs used as input data within a separate AI system those model outputs may be biased in some manner. For example, they may have higher error rates for marginalised groups. Data sets that are outdated or incomplete may also lead to inaccurate or inappropriate outcomes in an AI system. A data set may be incomplete if it contains insufficient data points or insufficient characteristics or details about individuals. A way to address these issues may be to obtain additional data. For example, an insurer may seek to acquire data that is up to date, more complete or more representative. Insurers should consider the costs, risks and benefits of obtaining additional data sets, as well as any alternative options. Aside from additional financial costs, collecting extensive personal information about customers might give rise to other reputational or legal risks, such as obligations under the Privacy Act 1988 Cth . In order to rely on the data exemption under the ADA, DDA, or SDA, it may be necessary for the insurer to obtain any data that is available or reasonably obtainable, where such data is reasonable to rely on. If an insurer does not have data from internal claims, they may not have sufficient data to rely on the data exemption,67 and may need data from external sources where it is reasonable to rely on such data. If such additional data cannot be reasonably obtained, then the no data exemption available under the ADA and DDA may apply. ii Preprocess the data Data preprocessing is an important and common step to address missing, incomplete or inaccurate data points. Raw data usually requires preprocessing before it can be effectively used to train an AI system. Preprocessing techniques help to ensure more reliable results. Provided they are used appropriately, they may also help to ensure less discriminatory results. Some preprocessing techniques include smoothing, which removes noise , such as outliers, corrupt or meaningless information, from data grouping data points, such as banding of age groups, or clustering detailed medical conditions under wider terms transformation, which turns the data into the proper format needed for analysis imputation, which replaces missing data with suitably substituted data. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 23  Insurers may need technical or actuarial advice regarding the availability, appropriateness and application of such techniques, taking into account the context of the model, and its materiality and effect on the outcomes of the model or AI system. For example, grouping middle aged people into cohorts of 5 years for travel insurance may be non controversial. However, for a product like motor insurance, where risk materially changes from ages 18 to 22, a finer level of grouping may be more appropriate. If the insurer is intending to rely on preprocessed data for an exemption under the ADA, DDA, or SDA, it must be reasonable for it to rely on the data as processed. Insurers should ensure that all processing steps are recorded and appropriately justified in the event that it needs to explain why it was reasonable for it to rely on the preprocessed data. iii Data relating to protected attributes The inclusion and selection of data relating to protected attributes is another important mitigation strategy. Noting that where the insurer satisfies the requirements of an applicable data exemption, it can include data relating to age, sex, or disability and discriminate on the basis of that data. However, it may be necessary for the insurer to remove data relating to other protected attributes. For example, whilst an insurer can discriminate based on data relating to age when calculating life insurance premiums, there is no exemption under the RDA that allows discrimination based on data relating to race. Preprocessing the data can also be used to edit features in the data set to mask or remove some information relating to protected attributes before it is used to train or score an algorithm. For example, to remove direct discrimination, an individual s sex could be hidden before it is used in model scoring, where the model is applied to the dataset. Alternatively, to protect against direct discrimination, an insurer might not collect or include any data relating to a protected attribute in its model or the decision making process. To remove indirect discrimination, other mitigating strategies can then be used. Ultimately, an AI system must be tested to determine whether the strategy employed actually avoids discriminatory outcomes. For example, simply hiding protected attributes from the data set may not be sufficient to prevent discrimination if as is likely in a sufficiently rich or granular dataset other pieces of information in the dataset act as proxy variables for that protected attribute. Where a proxy variable is known, it may be possible to remove the discriminatory effect via statistical techniques. However, again, this is an area of evolving practice, with conflicting views in the academic research, so careful consideration should be given to the techniques employed, and why they are justified. b Models In simple terms, a model is a tool or algorithm that utilises a set of data to recognise patterns and make decisions. It may be possible to design or adjust models to avoid discriminatory outcomes, such as by adjusting the design or parameters of the model, or by changing its complexity. Testing and ongoing monitoring of the model are important mitigation strategies against discrimination. To do so effectively, there may need to be an understanding of the reasons for the model s outputs, as well as human oversight of the model and its outputs. 4 Artificial Intelligence and discrimination 24   i Adjusting the model A model may be adjusted to avoid discriminatory outcomes. Different approaches may need to be tested into order to determine how to best avoid discriminatory outcomes. There may be different ways to adjust the model. One way could be to increase the complexity of the model. While simple models may be easier to test, monitor and interrogate, over simplified models will often be less accurate, particularly for minority groups within the population considered. Adding new parameters to increase the complexity of the model to allow it to identify and account for differences between groups may reduce potential algorithmic bias and increase accuracy.68 Testing the models on data sets prior to deployment will assist in identifying the impacts of complexity on accuracy and fairness. 69 However, the manner of any testing will require careful consideration of the circumstances of the model s use. ii Reasons Discriminatory outcomes can be less obvious and more difficult to detect in AI informed decision making, particularly where there are difficulties in providing reasons or explanations for AI informed decisions. This problem is often referred to as opaque or black box AI. The Australian Government s AI Ethics Principles is a voluntary framework for use of the AI and includes a principle of explainablity. This principle states that stakeholders should be provided with reasonable justifications for AI systems outcomes , including information that helps people understand outcomes, like key factors used in decision making .70 The reasons for a decision are important in assessing whether any discrimination was unlawful under the Discrimination Acts, particularly when the court is considering if a customer s treatment was because of their protected attribute or if any indirect discrimination was reasonable in circumstances. Moreover, explaining the reasons for a decision may help a customer understand why the insurer considers that its decision was not discriminatory, and potentially prevent a claim of discrimination being brought. iii Human oversight Issues with models may be addressed through human oversight. This is sometimes referred to as having a human in the loop . This can be a useful strategy to help identify and address problems that arise with AI informed decision making, particularly where the relevant human in the loop has sufficient technical knowledge and other relevant knowledge. However, such processes should also be closely monitored, given human decisions can also be affected by bias and discrimination. Human oversight may be used to review results, identify errors, consider whether a decision is discriminatory, or exercise discretion to avoid such outcomes. For example, this could be achieved by providing customers with the option of a human review of an automated decision.71 It is important that such staff have a good understanding of discrimination and the relevant obligations under the Discrimination Acts. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 25   5 Case Studies Challenges for insurers While the Discrimination Acts apply to all decisions made by insurers, AI informed decision making may raise novel challenges and uncertainty around what constitutes unlawful discrimination. This section uses case studies to explore challenges faced by insurers in avoiding discrimination and complying with the Discrimination Acts when using AI informed decision making. These hypothetical case studies are provided as simple examples, to aid understanding and illustrate some of the issues discussed above. While they are not exhaustive, they aim to illustrate a range of challenges in different areas of insurance, and to outline some general principles that may be applied to more complex situations and other circumstances. The case studies are not based on any actual experiences of insurers or any other individual experiences known to the Commission or the Institute. 5.1 Case Study Car Insurance This case study explores the challenges that arise when data is correlated with a protected attribute, which may be unseen, and identifying where further action may be required to avoid unlawful discrimination. a Part A Car Insurance Pty Ltd CIPL is considering how to price its car insurance policies. For simplicity, the following assumptions apply There are only two types of cars expensive cars and cheaper cars. The cost of repairing an expensive car is significantly more than the cost of repairing a cheaper car. All cars have the same probability of crashing during a policy period. As such, the expected cost of claims per car is significantly more for expensive cars compared to cheaper cars. CIPL is considering charging higher premiums for the drivers of expensive cars in accordance with the difference in the expected cost of claims. CIPL is concerned that there may be an unknown relationship between a protected attribute and the cost of the car people drive. It would be very difficult for CIPL to determine any such relationship on the available data. This unknown relationship might mean that people with certain protected attribute statuses Group A are more likely to drive the expensive car, whereas people without that protected attribute Group B are more likely to drive the cheaper car. If such a relationship exists, CIPL is concerned that charging higher premiums for the expensive cars may constitute discrimination against Group A. However, it is unlikely that CIPL will have engaged in unlawful discrimination by charging premiums as proposed. Is there direct discrimination There is no direct discrimination as Group A are not being treated differently from Group B because of, or by reason of, a protected attribute. The premium charged is due to the cost of repairing the car, and the relationship between the cost of the car and the protected attribute is unknown to CIPL. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 27  Is there indirect discrimination What is the requirement The first step is to determine the relevant requirement. A customer is not required to buy insurance from CIPL. For example, they could refuse the prices offered and apply to another insurer.72 However, the requirement might be described as a customer who purchases insurance from CIPL must drive a cheap car to be provided with the lower premium for their insurance policy. Indirect discrimination under the RDA requires that a person of a particular race, colour, descent, national or ethnic origin, or immigrant status does not or cannot comply with the requirement. If a person with protected attributes under the RDA does not drive a cheaper car, then they do not comply with the requirement. A successful claim under the DDA must show that because of their disability, a person does not, would not, is not able to, or would not be able to comply with this requirement. This may be satisfied in this situation if a person was not capable of driving cheaper cars because of their disability, which meant they could only drive expensive cars. For example, if a person with a disability required a special or modifiable vehicle. Does the requirement disadvantage people with a protected attribute The next step is to consider whether the requirement disadvantages people with the protected attribute. If people with certain disabilities can only drive expensive cars, then it could be argued that they are disadvantaged by this requirement, given they would not be able to access a policy at the lower premium. Any disadvantage suffered would be a matter for evidence and dependent on the particular circumstances. In a more realistic situation with a greater range of available vehicles, there would need to be careful consideration of a customer s ability to comply and any disadvantage arising from this requirement. However, for claims under the ADA, RDA, and SDA, there is no indication that people with protected attributes cannot drive cheaper cars or that they require expensive cars for any reason related to that protected attribute. Arguably, they are not disadvantaged by CIPL s requirement because they are able to drive a cheaper car and obtain the lower premium. Yet being able to technically comply with a requirement may not always be sufficient to establish that no disadvantage has been suffered. In some situations, it may be necessary to also consider whether a person is less likely to be able to comply with a requirement because of a protected attribute. Such questions would be a matter of evidence. In this case study, Group A are unlikely to be disadvantaged by this requirement as under the ADA or SDA. For similar reasons, this is unlikely to amount to impairing a person s human rights under the RDA. 5 Case Studies Challenges for insurers 28  Is the requirement reasonable in the circumstances Even if the above elements needed to establish indirect discrimination were satisfied for example, in the case of people with certain disabilities requiring expensive cars , the higher premiums charged to expensive car drivers may ultimately be considered reasonable in the circumstances. This is because the higher premiums are directly related to the increased costs of repairs. Where the risk to the insurer is greater, given the increased expected cost of repairs for expensive cars, it may be reasonable for the insurer to charge a higher premium.73 Conclusion The proposed pricing appears unlikely to amount to either direct or indirect discrimination. These conclusions rely on some important assumptions The relevant rating factor type of car has a clear and intuitive relationship to risk. The insurer setting prices in line with that difference in risk. The protected attribute has no direct bearing itself on risk. Customers with a protected attribute can change their risk behaviour as described by the rating factor i.e. they are able to purchase cheaper cars . In other situations, some of these assumptions may not hold. An insurer should take steps to ensure that any indirect discrimination which might emerge from their prices is reasonable in the circumstances. However, in some situations, the protected attribute itself may still have a measurable relationship with risk, as discussed in Part B below. Summary The correlation of insurance rating factors with protected attributes alone particularly if unknown will not necessarily constitute unlawful discrimination There will only be direct discrimination if a customer is treated differently because of, or by reason of, a protected attribute. Whether there is any unlawful indirect discrimination will depend on the nature of any requirement imposed, the customer s failure or inability to comply with it in relation to the RDA and DDA , whether the customer is disadvantaged by the requirement, and ultimately, whether the requirement is reasonable in the circumstances. If there is a greater risk arising from a rating factor, it may be reasonable for the insurer to charge a higher premium in accordance with that risk. An insurer may be more at risk of unlawfully discriminating if The insurer sets prices based on a rating factor with no clear and intuitive relationship to risk or in an arbitrary manner, such that the pricing may not be considered reasonable in the circumstances. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 29   Customers with protected attributes are disadvantaged by pricing based on that rating factor, particularly where customers are unable to make choices around their risk exposure described by that rating factor. b Part B Upon acquiring additional statistical data, CIPL discovers that people in Group A that is, people with a certain protected attribute are, on average, inherently less likely to have a car accident than people in Group B people without that attribute , regardless of the car they drive. Based on this information, the expected cost of claims will be greater for policyholders in Group B, compared to policyholders in Group A who drive equivalent cars. CIPL considers whether it should retain the same pricing as above or change its prices for customers based on their group membership. CIPL retains the same pricing CIPL s pricing in Part A only uses a model of repair cost i.e. drivers of expensive cars are charged higher premiums in accordance with the difference in the expected cost of claims , which would be unaffected by the effect of the protected attribute on claim frequency. However, in other situations, such as if CIPL were to extend their pricing analysis to include a model of claim frequency, best practice would be to carefully include Group A B status within the construction of this model, in order that the derived parameters from that model only reflected the effect of car type on claim frequency and not the effect of the protected attribute as well. Is there direct discrimination If CIPL retains the previous pricing outlined in Part A, there is no direct discrimination as Group A are not being treated differently from Group B because of, or by reason of, a protected attribute. The premium charged is still due to the expected cost of claims for each car. Is there indirect discrimination What is the requirement For a claim of indirect discrimination, the relevant requirement might be described as a customer who purchases insurance from CIPL must drive a cheaper car to be provided with the lower premium for their insurance policy, without reference to the riskiness of the driver arising from their membership of Group A or Group B. Similar questions would arise as discussed in Part A regarding whether customers with protected attributes did or could comply to establish a claim of indirect discrimination under the RDA and DDA. Does the requirement disadvantage people with a protected attribute Group A might argue in this situation that they are disadvantaged by the requirement that premiums are charged only in accordance with the cost of the car because, as they are inherently less risky, they are paying more than their fair price. 5 Case Studies Challenges for insurers 30  Is the requirement reasonable in the circumstances This will not constitute indirect discrimination if the current pricing is considered reasonable in the circumstances. Even if an alternative approach was possible, the key question is still reasonableness, not whether CIPL could have made a better or more informed decision.74 In determining reasonableness, the impact of the discriminatory effect would need to be weighed against the reasons for the requirement. Relevant factors include the difference in the riskiness of Group A and Group B the relative expected cost of claims from Group A and Group B the difficulties in implementing alternative pricing based on the riskiness of Group A and B, such as collecting information regarding group membership from customers, and whether the alternative policy would be discriminatory the relative difference between the current premiums and premiums under the alternative pricing. Group A might argue more generally that they are being treated unfairly, but that is a broader claim than unlawful discrimination. While that is outside the scope of this Guidance Resource, such complaints may still be relevant considerations for an insurer. CIPL charges premiums based on group membership If CIPL instead charged premiums in accordance with a person s membership in Group A or Group B, such that people in Group A were charged lower premiums than people in Group B who drove similar cars, then this might constitute direct discrimination against Group B. If the membership of Group B related to age, disability or sex, and CIPL based these premiums on actuarial or statistical data on which it was reasonable to rely which confirmed the increased risk of this group, they would likely be able to rely on the data exemption under the ADA, DDA, or SDA, provided any discrimination against Group B was considered reasonable having regard to the data and other relevant factors. If the membership of Group B related to race, colour, descent, national or ethnic origin, there is no data exemption. As such, CIPL may be in engaging in direct discrimination in breach of the RDA by charging different premiums on this basis. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 31  Summary Where a protected attribute has a distinct relationship with risk, and the insurer charges premiums to customers on the basis of that protected attribute For sex, disability, and age, any discrimination will not be unlawful provided the data exemption under SDA, DDA and ADA can be relied upon. For protected attributes under the RDA, as no data exemption is available for insurers, this is likely to constitute unlawful direct discrimination. Where a protected attribute has a distinct relationship with risk, even if the insurer does not use the protected attribute in price setting for example, if no insurance exemption applies , it may be at risk of unlawful indirect discrimination, as other correlated rating factors may still infer this relationship within a risk model. However This may be mitigated by careful use of the protected attribute in the construction or training of the risk model, where suitable data is available. There are a range of proposed methodologies for this in the academic literature.75 The insurer may not be able to mitigate against the effect of this protected attribute in price setting where no such data can be reasonably obtained about the protected attribute. The availability of such data is a factor that may be considered by the courts in determining whether the pricing being the requirement imposed for the purpose of the Discrimination Acts is reasonable in the circumstances and, hence, whether unlawful indirect discrimination has occurred. This scenario assumes that CIPL has statistical data that shows the riskiness of drivers from Group A and Group B. However, insurers will not necessarily have data clearly showing the risk factors of different groups and it may not be possible, or appropriate, to obtain such data. In such a situation, without relevant data, the insurer may not be aware of any potential discrimination and may not be able to mitigate against it. 5.2 Case Study Travel Insurance This case study explores common challenges for insurers when defining standard product constructs, terms and conditions which are reliant on data or models. Travel Insurance Pty Ltd TIPL is building a pricing model for a new travel insurance product. This product provides emergency health coverage for accident and sickness during travel. 5 Case Studies Challenges for insurers 32  Age is an important rating factor in such products, since older people are generally more at risk of health emergencies than younger people. TIPL is considering two separate product constructs One option is a simple product sold via a white label provider. A customer inputs their age, destination and travel duration to receive a product priced on these attributes, allowing a personalised price to reflect a customer s risk. Another option is for an embedded product where insurance is offered alongside other travel products, such as flights and accommodation. In this case, there are no explicit questions about age or trip duration. With no access to detailed information, customers receive the same price and as such products will include inherent cross subsidies between younger and older groups. The insurer aims to use the insurance exemptions under the ADA. Their data confirms that health risks increase as age increases, but data becomes sparse and unreliable above the age of 90. TIPL is unable to reasonably obtain additional data for people above the age of 90. For simplicity, this illustrative case study is focused on age and the ADA alone. However, from a practical perspective, elderly people may also be more likely than the general population to have health conditions of relevance to travel insurance underwriting and so the DDA may also be relevant to consider for travel insurers in this situation. White label provider As the data is sparse above age 90, the following options are considered for pricing A. A smooth extrapolation following the general exponential trend for people under 90, and ignoring the sparse, unreliable data for people over 90. It is argued that the extrapolation is justified given that age generally affects health in this manner. B. A smoothed approach using a different extrapolation method. Whilst it has a similar statistical accuracy to Option A, it results in significantly higher premiums for people over 90. C. A flat rate for people over 90. This group already pays the highest rate, and there is limited evidence in the data alone to justify continuing to increase prices over age 90. It is also noted that a greater proportion of people over 90 cannot travel because of their health. Unless an exemption applies, charging higher premiums to people over 90 may constitute direct discrimination on the basis of age. Given that TIPL does not have, and cannot reasonably obtain, actuarial or statistical data on which it is reasonable to rely, the insurer would not be able to rely on the data exemption under the ADA. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 33  However, the insurer may be able to rely on the no data exemption provided any such discrimination is reasonable having regard to other relevant factors. These factors may include practical and business considerations whether less discriminatory options were available the customer s particular circumstances the objects of the ADA, especially eliminating age discrimination all other relevant factors of the case. Option C may represent the least discriminatory option, given everyone over 90 will be treated equally. However, this will still need to be implemented carefully. For example, a sharp discontinuity at age 90 to a much higher average rate might be argued as unfair by someone aged 91. While insurers must be careful that any assumptions are based on reasonable evidence, it may be reasonable for TIPL to assume that health risks continue to increase as people age over 90, such that Option A is reasonable. Medical opinions, especially from those with medical assistance backgrounds, could be used to provide additional evidence for such assumptions. It is also less discriminatory than Option B, given the less significant increase in premiums. Option B poses the greatest risk of being discriminatory, given that it results in significantly higher premiums for people over 90, there is limited evidence to support it, and other less discriminatory options were available, such as Option C or Option A. Moreover, as a decreasing number of people over 90 travel, the significant premiums may also not be considered reasonable when weighing the impact on customers against the financial impact for the insurer. The circumstances of the individual are relevant in determining whether any discrimination is reasonable. In relation to the insurance exemption under the DDA, the courts have said that decision making processes which are formulaic or which tend to stereotype individuals by reference to their disability should be avoided.76 The courts may adopt a similar approach in relation to age. Further information about the customer seeking insurance, such as medical opinions, may be relevant in assessing whether they do present a significantly higher risk that justifies the significantly increased premium. Embedded product TIPL is considering a cut off, such as limiting access to certain claim types to people over 60 either in the form of a lower sum insured, higher excess, or exclusion of certain forms of claims altogether . Whilst information about age is not collected, these conditions would be made clear in the product documentation.77 TIPL believes that this will create a more affordable product which is fairer to the younger cohort than if the same product were to be offered to all age groups. However, there are concerns that an age cut off is not appropriate in all situations, given that some elderly people will be of similar health and hence similar risk to some younger people. 5 Case Studies Challenges for insurers 34  Providing a policy with such conditions may constitute direct discrimination against people over 60. TIPL would need to rely on the data exemption under the ADA to ensure it was lawful. As this discrimination is based upon actuarial or statistical data indicating that health risks increase with age, the key question is whether the age cut off is reasonable having regard to the matter of the data and other relevant factors. Relevant factors would include the nature and purpose of the product, medical opinions, the customer s circumstances, other professional opinions, actuarial advice or opinions, practice of others in the insurance industry, commercial judgement, and the relative number of customers under and over 60. Further, TIPL may also consider the impact of increasing the age cut off on the premium and the effect on younger customers. If the increase in the required cross subsidised premium was so significant as to make this product unattractive and uncompetitive compared to an age rated product, then this may help to justify the threshold selected. For example, if the increase in the required premium was only 5 to increase the age limit to 65, this may be more acceptable and hence should be more actively considered by TIPL than an increase in the required premium of 50 to increase the limit to 75. As the customer s circumstances may be a relevant factor, imposing conditions on the insurance may be seen as less reasonable for customers over 60 who are in excellent health. However, on balance, it may still be considered reasonable to impose such conditions given the circumstances in which the product is being sold, particularly if there are alternative products available in the marketplace which may be able to meet the needs of the older individuals. Summary Where data is limited, some approaches to price setting may be more discriminatory, and at greater risk of constituting unlawful discrimination. Insurers should consider the potential options available to them, and whether a more discriminatory option is justified, if less discriminatory options are available. If including a cut off based on a customer s age, the level of age threshold is again a matter of judgement for the insurer. Similar considerations may apply to other protected attributes in other situations. An insurer should carefully consider all relevant factors, including the availability and impact of a less discriminatory option on the whole population, in order to justify the threshold selected. 5.3 Case Study Life Insurance When data is added to a model, it frequently affects the fitted estimates of effects from other factors in that model. This may include protected factors an insurer is intending to rely on under an insurance exemption. This case examines this issue, and any resulting obligations on insurers to use or not use any available data. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 35  Life Insurance Pty Ltd LIPL is constructing a Generalised Linear Model GLM to price their term life insurance policies. A GLM is a common statistical model used in insurance pricing, allowing prediction of expected claims costs from historic claims and policy data. In conducting this analysis, LIPL observes that The inclusion of the occupation category data results in a material change to the fitted model s estimated effect of sex on risk. This means that including occupation categories such as professional or blue collar categories as an item of data in the analysis impacts the measured effect of a customer s sex on the expected mortality risks in term life insurance, and ultimately, the price proposed by the model. Similarly, a decision to split a particular occupation type into two subtypes further changes the sex relativities produced by the model. LIPL is debating whether to include occupation categories within the model. LIPL notes that if it chooses not to include occupation or occupation categories this will cause the premiums for lower risk males to be significantly greater than if occupation is included, as males tend to perform a higher proportion of riskier occupations than females, such as working in blue collar occupations. Should an insurer include all available data An insurer would not be expected to include all data it holds that may be correlated to risk in its model. Almost all information may have some impact on the model if it is included, and clearly it is unreasonable to require all data to be used or analysed merely because it may be available. The insurer must use their commercial judgement to decide what information to collect and include in their model. If the model results in discriminatory outcomes, provided such discrimination is based on data on which it is reasonable to rely and objectively reasonable, then the data exemption under the SDA should apply. By including a particular occupation category, LIPL may be able to deliver outcomes for its customers that might be considered fairer. The premium that people pay will be adjusted in accordance with their occupation category and the expected risks it entails for the insurance cover. However, occupation category data should be used carefully if it is correlated with other protected attributes. LIPL should be confident that the use of occupation category data is reasonable, having regard to all other protected factors. Does the data exemption apply The availability or not of the data exemption under the SDA in this case study is unlikely to turn on whether LIPL includes occupations and occupation categories in its analysis or not. Either practice may be defensible. It is assumed that statistical or actuarial data shows that men, all other things being equal, have a higher mortality rate than women for whatever potential reason and it is reasonable to rely on such data. The data exemption will apply if it is reasonable for LIPL to discriminate against men by charging them higher premiums for the higher expected risks. In determining whether this is reasonable, relevant factors may include the practice of others in the insurance industry, and the commercial judgement of LIPL behind this decision. 5 Case Studies Challenges for insurers 36  Importantly, such discrimination may still be reasonable, even if LIPL could have made alternative decisions, or even decisions that are considered fairer to some customers.78 Provided it is reasonable, the data exemption should apply and such discrimination would not be unlawful. The inclusion of occupations and occupation categories changes the nature of any possible discrimination. If included, the relevant question to determine whether any direct discrimination occurred becomes whether men with particular occupations are charged higher premiums than women with those same particular occupations. Again, provided this discrimination was supported by appropriate data and was reasonable, it is likely that the data exemption would apply. Conclusion There are many variables that could be included into the analysis that might change the outcome. As set out above, inclusion of occupation categories changes the outcomes, and the inclusion of additional occupation subtypes within the categories further changes the outcomes. Inclusion of other datasets might change outcomes further. Insurers must make decisions regarding the collection and inclusion of relevant data, and the design of the model. The availability of the data exemption depends on discrimination being based on appropriate data and being reasonable having regard to the matter and any other relevant factors, which will turn on the relevant circumstances of each case. Summary An insurer does not necessarily need to include all data relating to risk in its model, where correlated with a protected attribute covered by an insurance exemption. The insurance exemption requires reasonableness, not perfection. The existence of potentially better options including the existence of potentially relevant data which remained unused does not necessarily mean that any discrimination arising from chosen methodology is not reasonable. The data exemption will apply where any discrimination arising from the methodology was based on data on which it is reasonable to rely and was reasonable having regard to the data and other relevant factors. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 37   3. Ensure customers have a way to understand why higher premiums may apply and what they can do to reduce their risk exposure and hence their premiums. 4. Document decisions around insurance pricing, including the reasons for those decisions. This documentation will be helpful in explaining to the court, if necessary, why such decisions were made and why the insurer considers that they are reasonable. Such documentation may also be a valuable risk management tool, allowing greater transparency and understanding of pricing decisions within the insurer, which in turn may help identify any risks of unlawful discrimination. 5. Where appropriate, give reasons to customers for decisions. Explaining the reasons for a decision may help a customer understand why the insurer considers that its decision was not discriminatory, and potentially prevent a claim of discrimination being brought at all. An option for human review of automated decisions may also be a useful risk mitigation strategy for various issues, including discrimination. 6. Test and monitor models and their outputs. Test prices wherever possible to assess whether they might give rise to claims of indirect discrimination, particularly whether such pricing decisions would be considered reasonable in the circumstances. Monitoring processes may include automated and human routines. 7. Ensure relevant decision making staff are suitably trained in concepts of discrimination. 8. An insurer should seek legal advice where it is unsure of the correct course of action and is concerned about breaching anti discrimination legislation. The following are practical tips for insurers to help minimise the risks of a successful discrimination claim when using AI for insurance pricing and underwriting 1. Consider carefully whether and how protected attributes are likely to be related to risk for the type of insurance at hand. These considerations should where possible be based on data. If such a relationship is likely a. For protected attributes with an insurance exemption, collect data on which it is reasonable to rely, and base any discrimination upon that data, in accordance with the requirements of the data exemption. If such additional data cannot be reasonably obtained, consider whether the no data exemption might apply. b. For protected attributes without an insurance exemption, the protected attribute should not be used directly in price setting. An insurer should also take suitable steps to ensure its prices are reasonable and not indirectly discriminatory. This may include use of that protected attribute within underlying pricing models, where data is available, to test for or mitigate against indirect discrimination. 2. Check data for representativeness, accuracy, errors, omissions or other issues. Model outputs that are used as input data for insurance risk models should be checked similarly. If issues are identified with the data a. Data may be preprocessed to address certain issues such as missing values or errors. b. An insurer might consider obtaining more or different data, if there are issues of representativeness, biases in accuracy, or other structural issues which may disproportionately impact protected groups. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 39 6 Practical tips to avoid unlawful discrimination when using AI   Further Resources Australian Human Rights Commission National Information Service The Commission s National Information Service provides information and referrals for individuals, organisations and employers about a range of human rights and discrimination issues. Phone 1300 656 419 or 02 9284 9888 to access this service. Complaints process The Commission can also investigate complaints about discrimination and other human rights breaches. The complaints process is simple, free and flexible. For further information on the complaints process please visit the Commission s website. Commission publications The following publications by the Commission provide further information and guidance in relation to AI and or discrimination Using artificial intelligence to make decisions Addressing the problem of algorithmic bias 2020 work disability rights guidelines providers insurance and superannuation under disability Guidelines for providers of insurance and superannuation under the Disability Discrimination Act 1992 Cth 2016 humanrights.gov.au our work disability rights guidelines providers insurance and superannuation under disability Federal Discrimination Law 2016 publications federal discrimination law 2016. In addition, the Commission can provide assistance in the form of diversity and inclusion training workshops and educational resources. For more information, please contact us by sending an email to training humanrights.gov.au. Actuaries Institute of Australia The following documents from the Institute provide further information and guidance in relation to AI, data and or discrimination Actuaries Institute Response to Human Rights and Technology Discussion Paper 10 March 2020 Submissions 2020 2020AHRC.pdf The Australian Anti Discrimination Act Information and Practical Suggestions for Actuaries August 2020 actuaries.logicaldoc.cloud download ticket ticketId 0d5870d6 2acc 4c74 8bce d01afd0eba8f Big Data and the digital economy Benefits and pitfalls in the insurance industry March 2022 Opinion 2022 ABSDataPaper.pdf Other resources include the following academic papers Frees, Edward W. Huang, Fei The Discriminating Pricing Actuary 2021 North American Actuarial Journal 10.1080 10920277.2021.1951296 Xin, Xi and Huang, Fei Anti Discrimination Insurance Pricing Regulations, Fairness Criteria, and Models 2022 com abstract 3850420 or org 10.2139 ssrn.3850420 State and territory human rights commissions Links to each of the state and territory human rights commission or agencies can be found in section 3.5 above or on the Commission s website at around states and territories. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 41   Appendix 1 Key sections under the Discrimination Acts c the condition, requirement or practice has, or is likely to have, the effect of disadvantaging persons of the same age as the aggrieved person. 2 For the purposes of paragraph  1 b , the burden of proving that the condition, requirement or practice is reasonable in the circumstances lies on the discriminator. 7 Superannuation, insurance and credit actuarial data etc. Superannuation and insurance 1 Subsections 2 and 3 apply to the following a an annuity b a life insurance policy c a policy of insurance against accident or any other policy of insurance d membership of a superannuation or provident fund e membership of a superannuation or provident scheme. 2 This Part does not make it unlawful for a person to discriminate against another person, on the ground of the other person s age a in respect of the terms or conditions on which the annuity, policy or membership is offered to, or may be obtained by, the other person or b by refusing to offer the annuity, policy or membership to the other person if the condition in subsection 3 is satisfied. Age Discrimination Act 2004 Cth 14 Discrimination on the ground of age direct discrimination For the purposes of this Act, a person the discriminator discriminates against another person the aggrieved person on the ground of the age of the aggrieved person if a the discriminator treats or proposes to treat the aggrieved person less favourably than, in circumstances that are the same or are not materially different, the discriminator treats or would treat a person of a different age and b the discriminator does so because of i the age of the aggrieved person or ii a characteristic that appertains generally to persons of the age of the aggrieved person or iii a characteristic that is generally imputed to persons of the age of the aggrieved person. 15 Discrimination on the ground of age indirect discrimination 1 For the purposes of this Act, a person the discriminator discriminates against another person the aggrieved person on the ground of the age of the aggrieved person if a the discriminator imposes, or proposes to impose, a condition, requirement or practice and b the condition, requirement or practice is not reasonable in the circumstances and Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 43   3 The condition is satisfied if a the discrimination i is based upon actuarial or statistical data on which it is reasonable for the first mentioned person to rely and ii is reasonable having regard to the matter of the data and other relevant factors or Note The Commission and the President can require the disclosure of the source of the actuarial or statistical data see section 54 . b in a case where no such actuarial or statistical data is available and cannot reasonably be obtained the discrimination is reasonable having regard to any other relevant factors. Disability Discrimination Act 1992 Cth 5 Direct disability discrimination 1 For the purposes of this Act, a person the discriminator discriminates against another person the aggrieved person on the ground of a disability of the aggrieved person if, because of the disability, the discriminator treats, or proposes to treat, the aggrieved person less favourably than the discriminator would treat a person without the disability in circumstances that are not materially different. 2 For the purposes of this Act, a person the discriminator also discriminates against another person the aggrieved person on the ground of a disability of the aggrieved person if a the discriminator does not make, or proposes not to make, reasonable adjustments for the person and b the failure to make the reasonable adjustments has, or would have, the effect that the aggrieved person is, because of the disability, treated less favourably than a person without the disability would be treated in circumstances that are not materially different. 3 For the purposes of this section, circumstances are not materially different because of the fact that, because of the disability, the aggrieved person requires adjustments. 6 Indirect disability discrimination 1 For the purposes of this Act, a person the discriminator discriminates against another person the aggrieved person on the ground of a disability of the aggrieved person if a the discriminator requires, or proposes to require, the aggrieved person to comply with a requirement or condition and b because of the disability, the aggrieved person does not or would not comply, or is not able or would not be able to comply, with the requirement or condition and c the requirement or condition has, or is likely to have, the effect of disadvantaging persons with the disability. 2 For the purposes of this Act, a person the discriminator also discriminates against another person the aggrieved person on the ground of a disability of the aggrieved person if a the discriminator requires, or proposes to require, the aggrieved person to comply with a requirement or condition and Appendix 1 Key sections under the Acts 44   b because of the disability, the aggrieved person would comply, or would be able to comply, with the requirement or condition only if the discriminator made reasonable adjustments for the person, but the discriminator does not do so or proposes not to do so and c the failure to make reasonable adjustments has, or is likely to have, the effect of disadvantaging persons with the disability. 3 Subsection 1 or 2 does not apply if the requirement or condition is reasonable, having regard to the circumstances of the case. 4 For the purposes of subsection 3 , the burden of proving that the requirement or condition is reasonable, having regard to the circumstances of the case, lies on the person who requires, or proposes to require, the person with the disability to comply with the requirement or condition. 46 Superannuation and insurance 1 This Part does not render it unlawful for a person to discriminate against another person, on the ground of the other person s disability, by refusing to offer the other person a an annuity or b a life insurance policy or c a policy of insurance against accident or any other policy of insurance or d membership of a superannuation or provident fund or e membership of a superannuation or provident scheme if f the discrimination i is based upon actuarial or statistical data on which it is reasonable for the first mentioned person to rely and ii is reasonable having regard to the matter of the data and other relevant factors or g in a case where no such actuarial or statistical data is available and cannot reasonably be obtained the discrimination is reasonable having regard to any other relevant factors. 2 This Part does not render it unlawful for a person to discriminate against another person, on the ground of the other person s disability, in respect of the terms or conditions on which a an annuity or b a life insurance policy or c a policy of insurance against accident or any other policy of insurance or d membership of a superannuation or provident fund or e membership of a superannuation or provident scheme is offered to, or may be obtained by, the other person, if f the discrimination i is based upon actuarial or statistical data on which it is reasonable for the first mentioned person to rely and Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 45   ii is reasonable having regard to the matter of the data and other relevant factors or g in a case where no such actuarial or statistical data is available and cannot reasonably be obtained the discrimination is reasonable having regard to any other relevant factors. Racial Discrimination Act 1975 Cth 9 Racial discrimination to be unlawful 1 It is unlawful for a person to do any act involving a distinction, exclusion, restriction or preference based on race, colour, descent or national or ethnic origin which has the purpose or effect of nullifying or impairing the recognition, enjoyment or exercise, on an equal footing, of any human right or fundamental freedom in the political, economic, social, cultural or any other field of public life. 1A Where a a person requires another person to comply with a term, condition or requirement which is not reasonable having regard to the circumstances of the case and b the other person does not or cannot comply with the term, condition or requirement and c the requirement to comply has the purpose or effect of nullifying or impairing the recognition, enjoyment or exercise, on an equal footing, by persons of the same race, colour, descent or national or ethnic origin as the other person, of any human right or fundamental freedom in the political, economic, social, cultural or any other field of public life the act of requiring such compliance is to be treated, for the purposes of this Part, as an act involving a distinction based on, or an act done by reason of, the other person s race, colour, descent or national or ethnic origin. 13 Provision of goods and services It is unlawful for a person who supplies goods or services to the public or to any section of the public a to refuse or fail on demand to supply those goods or services to another person or b to refuse or fail on demand to supply those goods or services to another person except on less favourable terms or conditions than those upon or subject to which he or she would otherwise supply those goods or services by reason of the race, colour or national or ethnic origin of that other person or of any relative or associate of that other person. Sex Discrimination Act 1984 Cth 5 Sex discrimination 1 For the purposes of this Act, a person in this subsection referred to as the discriminator discriminates against another person in this subsection referred to as the aggrieved person on the ground of the sex of the aggrieved person if, by reason of a the sex of the aggrieved person b a characteristic that appertains generally to persons of the sex of the aggrieved person or c a characteristic that is generally imputed to persons of the sex of the aggrieved person Appendix 1 Key sections under the Acts 46  the discriminator treats the aggrieved person less favourably than, in circumstances that are the same or are not materially different, the discriminator treats or would treat a person of a different sex. 2 For the purposes of this Act, a person the discriminator discriminates against another person the aggrieved person on the ground of the sex of the aggrieved person if the discriminator imposes, or proposes to impose, a condition, requirement or practice that has, or is likely to have, the effect of disadvantaging persons of the same sex as the aggrieved person. 3 This section has effect subject to sections 7B and 7D. 5A Discrimination on the ground of sexual orientation 1 For the purposes of this Act, a person the discriminator discriminates against another person the aggrieved person on the ground of the aggrieved person s sexual orientation if, by reason of a the aggrieved person s sexual orientation or b a characteristic that appertains generally to persons who have the same sexual orientation as the aggrieved person or c a characteristic that is generally imputed to persons who have the same sexual orientation as the aggrieved person the discriminator treats the aggrieved person less favourably than, in circumstances that are the same or are not materially different, the discriminator treats or would treat a person who has a different sexual orientation. 2 For the purposes of this Act, a person the discriminator discriminates against another person the aggrieved person on the ground of the aggrieved person s sexual orientation if the discriminator imposes, or proposes to impose, a condition, requirement or practice that has, or is likely to have, the effect of disadvantaging persons who have the same sexual orientation as the aggrieved person. 3 This section has effect subject to sections 7B and 7D. 5B Discrimination on the ground of gender identity 1 For the purposes of this Act, a person the discriminator discriminates against another person the aggrieved person on the ground of the aggrieved person s gender identity if, by reason of a the aggrieved person s gender identity or b a characteristic that appertains generally to persons who have the same gender identity as the aggrieved person or c a characteristic that is generally imputed to persons who have the same gender identity as the aggrieved person the discriminator treats the aggrieved person less favourably than, in circumstances that are the same or are not materially different, the discriminator treats or would treat a person who has a different gender identity. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 47   2 For the purposes of this Act, a person the discriminator discriminates against another person the aggrieved person on the ground of the aggrieved person s gender identity if the discriminator imposes, or proposes to impose, a condition, requirement or practice that has, or is likely to have, the effect of disadvantaging persons who have the same gender identity as the aggrieved person. 3 This section has effect subject to sections 7B and 7D. 5C Discrimination on the ground of intersex status 1 For the purposes of this Act, a person the discriminator discriminates against another person the aggrieved person on the ground of the aggrieved person s intersex status if, by reason of a the aggrieved person s intersex status or b a characteristic that appertains generally to persons of intersex status or c a characteristic that is generally imputed to persons of intersex status the discriminator treats the aggrieved person less favourably than, in circumstances that are the same or are not materially different, the discriminator treats or would treat a person who is not of intersex status. 2 For the purposes of this Act, a person the discriminator discriminates against another person the aggrieved person on the ground of the aggrieved person s intersex status if the discriminator imposes, or proposes to impose, a condition, requirement or practice that has, or is likely to have, the effect of disadvantaging persons of intersex status. 3 This section has effect subject to sections 7B and 7D. 6 Discrimination on the ground of marital or relationship status 1 For the purposes of this Act, a person in this subsection referred to as the discriminator discriminates against another person in this subsection referred to as the aggrieved person on the ground of the marital or relationship status of the aggrieved person if, by reason of a the marital or relationship status of the aggrieved person or b a characteristic that appertains generally to persons of the marital or relationship status of the aggrieved person or c a characteristic that is generally imputed to persons of the marital or relationship status of the aggrieved person the discriminator treats the aggrieved person less favourably than, in circumstances that are the same or are not materially different, the discriminator treats or would treat a person of a different marital or relationship status. 2 For the purposes of this Act, a person the discriminator discriminates against another person the aggrieved person on the ground of the marital or relationship status of the aggrieved person if the discriminator imposes, or proposes to impose, a condition, requirement or practice that has, or is likely to have, the effect of disadvantaging persons of the same marital or relationship status as the aggrieved person. 3 This section has effect subject to sections 7B and 7D. Appendix 1 Key sections under the Acts 48  7 Discrimination on the ground of pregnancy or potential pregnancy 1 For the purposes of this Act, a person the discriminator discriminates against a woman the aggrieved woman on the ground of the aggrieved woman s pregnancy or potential pregnancy if, because of a the aggrieved woman s pregnancy or potential pregnancy or b a characteristic that appertains generally to women who are pregnant or potentially pregnant or c a characteristic that is generally imputed to women who are pregnant or potentially pregnant the discriminator treats the aggrieved woman less favourably than, in circumstances that are the same or are not materially different, the discriminator treats or would treat someone who is not pregnant or potentially pregnant. 2 For the purposes of this Act, a person the discriminator discriminates against a woman the aggrieved woman on the ground of the aggrieved woman s pregnancy or potential pregnancy if the discriminator imposes, or proposes to impose, a condition, requirement or practice that has, or is likely to have, the effect of disadvantaging women who are pregnant or potentially pregnant. 3 This section has effect subject to sections 7B and 7D. 7AA Discrimination on the ground of breastfeeding 1 For the purposes of this Act, a person the discriminator discriminates against a woman the aggrieved woman on the ground of the aggrieved woman s breastfeeding if, by reason of a the aggrieved woman s breastfeeding or b a characteristic that appertains generally to women who are breastfeeding or c a characteristic that is generally imputed to women who are breastfeeding the discriminator treats the aggrieved woman less favourably than, in circumstances that are the same or are not materially different, the discriminator treats or would treat someone who is not breastfeeding. 2 For the purposes of this Act, a person the discriminator discriminates against a woman the aggrieved woman on the ground of the aggrieved woman s breastfeeding if the discriminator imposes, or proposes to impose, a condition, requirement or practice that has, or is likely to have, the effect of disadvantaging women who are breastfeeding. 3 To avoid doubt, a reference in this Act to breastfeeding includes the act of expressing milk. 4 To avoid doubt, a reference in this Act to breastfeeding includes a an act of breastfeeding and b breastfeeding over a period of time. 5 This section has effect subject to sections 7B and 7D. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 49  7A Discrimination on the ground of family responsibilities For the purposes of this Act, an employer discriminates against an employee on the ground of the employee s family responsibilities if a the employer treats the employee less favourably than the employer treats, or would treat, a person without family responsibilities in circumstances that are the same or not materially different and b the less favourable treatment is by reason of i the family responsibilities of the employee or ii a characteristic that appertains generally to persons with family responsibilities or iii a characteristic that is generally imputed to persons with family responsibilities. 7B Indirect discrimination reasonableness test 1 A person does not discriminate against another person by imposing, or proposing to impose, a condition, requirement or practice that has, or is likely to have, the disadvantaging effect mentioned in subsection 5 2 , 5A 2 , 5B 2 , 5C 2 , 6 2 , 7 2 or 7AA 2 if the condition, requirement or practice is reasonable in the circumstances. 2 The matters to be taken into account in deciding whether a condition, requirement or practice is reasonable in the circumstances include a the nature and extent of the disadvantage resulting from the imposition, or proposed imposition, of the condition, requirement or practice and b the feasibility of overcoming or mitigating the disadvantage and c whether the disadvantage is proportionate to the result sought by the person who imposes, or proposes to impose, the condition, requirement or practice. 41 Insurance 1 Nothing in Division 1 or 2 makes discrimination by one person in this subsection called the insurer against another person in this subsection called the client unlawful if a the discrimination is on the ground of the client s sex and b the discrimination is in the terms on which an insurance policy is offered to, or may be obtained by, the client and c the discrimination is based on actuarial or statistical data from a source on which it is reasonable for the insurer to rely and d the discrimination is reasonable having regard to the data and e if the client gives the insurer a written request for access to the data either i the insurer gives the client a document containing the data or Appendix 1 Key sections under the Acts 50   ii the insurer A makes a document containing the data available for inspection by the client at such time or times, and at such place or places, as are reasonable and B if the client inspects the document allows the client to make a copy of, or take extracts from, the document. 1A Paragraph 1 e does not apply if the Commission has, under section 44, granted an exemption from the operation of that paragraph. 2 In this section insurance policy includes an annuity, a life assurance policy, an accident insurance policy and an illness insurance policy. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 51  1 Australian Human Rights Commission, Human Rights and Technology Final Report 2021 , 37. 2 Actuaries Institute, Actuaries Institute Response to Human Rights and Technology Discussion Paper 10 March 2020 Submissions 2020 2020AHRC.pdf. 3 Dolman et al 2020 , The Australian Anti Discrimination Acts Information and Practical Suggestions for Actuaries. All Actuaries Virtual Summit 2020. 4 Anti Discrimination Act 1977 NSW Equal Opportunity Act 2010 Vic Anti Discrimination Act 1991 Qld Equal Opportunity Act 1984 SA Equal Opportunity Act 1984 WA Anti Discrimination Act 1998 Tas and Anti Discrimination Act 1992 NT . 5 Age Discrimination Act 2004 Cth ss 14 15, Part 4. 6 Disability Discrimination Act 1992 Cth s 5 6, Part 2. 7 Racial Discrimination Act 1975 Cth ss 5 and 9. 8 Sex Discrimination Act 1984 Cth s 5 7A, Part II, Division 1 2. 9 Age Discrimination Act 2004 Cth s 14 Disability Discrimination Act 1992 Cth s 5 Racial Discrimination Act 1975 Cth s 9 Sex Discrimination Act 1984 Cth ss 5 7A. 10 Age Discrimination Act 2004 Cth s 16 Disability Discrimination Act 1992 Cth s 10 Racial Discrimination Act 1975 Cth s 18 Sex Discrimination Act 1984 Cth s 8. 11 Age Discrimination Act 2004 Cth s 15 Disability Discrimination Act 1992 Cth s6 Racial Discrimination Act 1975 Cth s 9 Sex Discrimination Act 1984 Cth ss 5 7B. 12 Age Discrimination Act 2004 Cth s 15 Disability Discrimination Act 1992 Cth s6 Racial Discrimination Act 1975 Cth s 9 Sex Discrimination Act 1984 Cth s 7B. 13 Waters v Public Transport Corporation 1991 173 CLR 349, 393 Dawson and Toohey JJ , 406 407 McHugh J Styles v Secretary, Department of Foreign Affairs and Trade 1988 84 ALR 408, 422 423 Mayer v Australian Nuclear Science and Technology Organisation 2003 FMCA 209, 72 73 Clarke v Catholic Education Office 2003 202 ALR 340, 351 44 Hinchliffe v University of Sydney 2004 FMCA 85, 105 106 Daghlian v Australian Postal Corporation 2003 FCA 759, 110 Trindall v NSW Commissioner of Police 2005 FMCA 2, 175 Munday v Commonwealth No. 2 2014 226 FCR 199, 226 132 Katzman J Mulligan v Virgin Australia Airlines Pty Ltd 2015 234 FCR 207, 248 153 Flick, Reeves and Griffith JJ . 14 Waters v Public Transport Corporation 1991 173 CLR 349, 393, 406 407 Catholic Education Office v Clarke 2004 138 FCR 121, 143 103 Sievwright v Victoria 2012 FCA 118 174 Nojin v Commonwealth 2012 208 FCR 1, 4 9 Buchanan J 52 176 70 234 Mulligan v Virgin Australia Airlines Pty Ltd 2015 234 FCR 207, 248 153 . 15 Waters v Public Transport Corporation 1991 173 CLR 349, 407 McHugh J . 16 Australian Medical Council v Wilson 1996 68 FCR 46. 17 For example, see Travers v New South Wales 2000 FCA 1565, 17 . 18 Mandla v Dowell Lee 1983 2 AC 548 Australian Medical Council v Wilson 1996 68 FCR 46, 80 Travers v New South Wales 2001 FMCA 18, 17 Clarke v Catholic Education Office 2003 FCA 1085, 49 . 19 Clarke v Catholic Education Office 2003 FCA 1085, 49 upheld on appeal, Catholic Education Office v Clarke 2004 128 FCR 121 Hurst v Queensland 2006 FCR 561, 580 106 , 585 134 . 20 Racial Discrimination Act 1975 Cth s 9 1A . 21 For example, Kleinberg, J., Mullainathan, S., Raghavan, M. Inherent trade offs in the fair determination of risk scores , 2016 arXiv preprint arXiv 1609.05807 Dolman, C. Semenovich, D. Algorithmic Fairness Some Practical Considerations for Actuaries. Actuaries Summit 2019 downloadticket ticketId e548493a 31d4 4099 a572 6a4eeebf5d. 22 Secretary, Department of Foreign Affairs Trade v Styles 1989 23 FCR 251, 263 Australian Medical Council v Wilson 1996 68 FCR 46, 60 Waters v Public Transport Corporation 1991 173 CLR 349 reasonableness under DDA Barngarla Determination Aboriginal Corp RNTBC v District Council of Kimba 2019 FCA 1092. 23 Waters v Public Transport Corporation 1991 173 CLR 349, 395. 24 Waters v Public Transport Corporation 1991 173 CLR 349, 395 Sklavos v Australasian College of Dermatologists 2016 FCA 179. 25 Waters v Public Transport Corporation 1991 173 CLR 349, 363 364, 378, 395. 26 Commonwealth Bank of Australia v Human Rights and Equal Opportunity Commission 1997 80 FCR 78, 88 State of Victoria v Schou 2004 8 VR 120, 26 . 27 Waters v Public Transport Corporation 1991 173 CLR 349, 378. Endnotes 52  28 Whilst there has been greater judicial consideration of reasonableness in the context of the SDA or DDA, these decisions are likely to be relevant when considering reasonableness under the RDA or ADA. 29 Sex Discrimination Act 1984 Cth s 7B Secretary, Department of Foreign Affairs Trade v Styles 1989 23 FCR 251 Catholic Education Office v Clarke 2004 138 FCR 121 Commonwealth Bank of Australia v Human Rights and Equal Opportunity Commission 1997 80 FCR 78. 30 Secretary, Department of Foreign Affairs Trade v Styles 1989 23 FCR 251, 263 Australian Medical Council v Wilson 1996 68 FCR 46, 60 Catholic Education Office v Clarke 2004 138 FCR 121. 31 Commonwealth v Human Rights and Equal Opportunity Commission 1995 63 FCR 74, 87 Australian Medical Council v Wilson 1996 68 FCR 46, 60 Commonwealth Bank of Australia v Human Rights and Equal Opportunity Commission 1997 80 FCR 78, 111. 32 Commonwealth v Human Rights and Equal Opportunity Commission 1995 63 FCR 74, 87 Australian Medical Council v Wilson 1996 68 FCR 46, 61 Commonwealth Bank of Australia v Human Rights and Equal Opportunity Commission 1997 80 FCR 78, 112. 33 Age Discrimination Act 2004 Cth s 15 2 Disability Discrimination Act 1992 Cth s 6 4 Sex Discrimination Act 1984 Cth s 7C. 34 Australian Medical Council v Wilson 1996 68 FCR 46, 62 35 Age Discrimination Act 2004 Cth s 28 Disability Discrimination Act 1992 Cth s 24 Racial Discrimination Act 1975 Cth s 13 Sex Discrimination Act 1984 Cth s 22. 36 Age Discrimination Act 2004 Cth s 5 Disability Discrimination Act 1992 Cth s 4 Racial Discrimination Act 1975 Cth s 3 Sex Discrimination Act 1984 Cth s 4. 37 Age Discrimination Act 2004 Cth s 28 Disability Discrimination Act 1992 Cth s 24 Racial Discrimination Act 1975 Cth s 13 Sex Discrimination Act 1984 Cth s 22. 38 Australian Human Rights Commission, Guidelines for providers of insurance and superannuation under the Disability Discrimination Act 1992 Cth 2016 . 39 Age Discrimination Act 2004 Cth s 37. 40 Disability Discrimination Act 1992 Cth s 46. 41 Disability Discrimination Act 1992 Cth s 107 Age Discrimination Act 2004 Cth s 87. 42 QBE Travel Insurance v Bassanelli 2004 137 FCR 88, 30 . 43 QBE Travel Insurance v Bassanelli 2004 137 FCR 88, 30 . 44 For example, see discussion of the reasonableness of different studies and data sources in Ingram v QBE Insurance Australia Ltd Human Rights 2015 VCAT 1936, 182 . 45 Xiros v Fortis Life Assurance Ltd 2001 FMCA 15 6 April 2001 16 k . 46 QBE Travel Insurance v Bassanelli 2004 137 FCR 88, 53 . 47 This Guidance Resource is intended to provide general advice and does not specifically examine issues for insurers relating to gender identity, such as data collection and discrimination. It is acknowledged that there may need a need for separate guidance on these issues. 48 Sex Discrimination Act 1984 Cth s 87. 49 Sex Discrimination Act 1984 Cth s 41 1 e . 50 Disability Discrimination Act 1992 Cth s 29A. 51 Disability Discrimination Act 1992 Cth s 11. 52 Ingram v QBE Insurance Australia Ltd 2015 VCAT 1936, 127 . 53 Discrimination Act 1991 ACT , Anti Discrimination Act 1977 NSW , Anti Discrimination Act 1992 NT , Anti Discrimination Act 1991 Qld , Equal Opportunity Act 1984 SA , Anti Discrimination Act 1998 Tas , Equal Opportunity Act 2010 Vic , Equal Opportunity Act 1984 WA . 54 Age Discrimination Act 2004 Cth s 12 Disability Discrimination Act 1992 Cth s 13 Racial Discrimination Act 1975 Cth s 6A Sex Discrimination Act 1984 Cth s 10. 55 The Actuaries Institute Anti Discrimination Working Group s The Australian Anti Discrimination Acts Information and Practical Suggestions for Actuaries August 2020 available at logicaldoc.cloud download ticket ticketId 0d5870d6 2acc 4c74 8bce d01afd0eba8f includes a summary table of protected attributes under state or territory legislation at section 2.7. 56 Resources on discrimination in the ACT available at 57 Resources on discrimination in NSW available at discrimination nsw discrimination.html. Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 53  58 Resources on discrimination in NT available at 59 Resources on discrimination in Queensland available at discrimination law. 60 Resources on discrimination in SA available at discrimination. 61 Resources on discrimination and exceptions in Tasmania available at equalopportunity.sa.gov.au discrimination equalopportunity.tas.gov.au exceptions. 62 Resources on discrimination and exceptions in Victoria available at vic.gov.au for individuals discrimination exceptions . 63 Resources on discrimination in WA available at Unlawful 20Discrimination 20Fact 20Sheet 20 2022 20March.2.pdf. 64 Australian Human Rights Commission, Human Rights and Technology Final Report 2021 , 37. 65 Australian Human Rights Commission, Human Rights and Technology Final Report 2021 , 101, 105. 66 Xiros v Fortis Life Assurance Ltd 2001 FMCA 15 6 April 2001 16 k . 67 For example, see Ingram v QBE Insurance Australia Ltd Human Rights 2015 VCAT 1936 18 December 2015 . 68 Australian Human Rights Commission, Using Artificial Intelligence to Make Decisions Addressing the Problem of Algorithmic Bias Technical Paper, November 2020 , 27. 69 Australian Human Rights Commission, Using Artificial Intelligence to Make Decisions Addressing the Problem of Algorithmic Bias Technical Paper, November 2020 , 27. 70 Australian Government, Department of Industry, Innovation and Science, AI Ethics Framework November 2019 publications australias artificial intelligence ethics framework . 71 Australian Human Rights Commission, Human Rights and Technology Final Report 2021 , 159. 72 Douglas v Department of Land and Housing 2011 FMCA 1028 22 December 2011 , 59 61. 73 QBE Travel Insurance v Bassanelli 2004 FCA 396, 34 . 74 Commonwealth v Human Rights and Equal Opportunity Commission 1995 63 FCR 74, 87 Australian Medical Council v Wilson 1996 68 FCR 46, 60 Commonwealth Bank of Australia v Human Rights and Equal Opportunity Commission 1997 80 FCR 78, 111. 75 A recent example in the actuarial literature can be seen in Lindholm, M., Richman, R., Tsanakas, A., Wüthrich, M. Discrimination Free Insurance Pricing 2022 ASTIN Bulletin, 52 1 , 55 89. 76 QBE Travel Insurance v Bassanelli 2004 137 FCR 88, 85 . 77 Insurers must provide a product disclosure statement PDS for every financial services product they offer. The regulatory standards for PDSs are set by the Australian Securities and Investments Commission ASIC to ensure that they are clear, accurate and comprehensive, and include information on any exclusions, caps, limits and other conditions. Further information is available from ASIC a document regulatory guides rg 168 disclosure product disclosure statements and other disclosure obligations 78 Commonwealth v Human Rights and Equal Opportunity Commission 1995 63 FCR 74, 87 Australian Medical Council v Wilson 1996 68 FCR 46, 60 Commonwealth Bank of Australia v Human Rights and Equal Opportunity Commission 1997 80 FCR 78, 111. Endnotes 54  Guidance Resource Artificial intelligence and discrimination in insurance pricing and underwriting 2022 55  Australian Human Rights Commission Actuaries Institute 